{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07886646",
   "metadata": {},
   "source": [
    "# 03_prepare_final (housing / CSV)\n",
    "**Authors**: <fill names> | **Owner**: <name> | **Reviewer**: <name> | **Date**: 2025-11-07\n",
    "\n",
    "**Purpose:** Deterministic pipeline CSV -> CSV\n",
    "\n",
    "> These notebooks assume the first ingest saved **CSV** outputs into `intermediate_data/` (not Parquet).\n",
    "> Paths used:\n",
    "> - Raw CSV: `price_paid_records/price_paid_records.csv`\n",
    "> - Combined CSV: `intermediate_data/housing_all.csv`\n",
    "> - Optional partitioned by year: `intermediate_data/partitioned_csv/year=YYYY.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2fd91b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\User\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fed4b40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10132\\3682294115.py:37: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[\"price\"] = df.groupby([\"region\",\"month\"])[\"price\"].transform(lambda s: s.fillna(s.median()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: processed_data\\housing_model_ready.csv rows: 21550209 cols: 6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "INT_DIR = Path(\"intermediate_data\")\n",
    "PROC_DIR = Path(\"processed_data\")\n",
    "PROC_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "csv_path = INT_DIR / \"housing_all.csv\"\n",
    "assert csv_path.exists(), f\"Expected combined CSV at: {csv_path}\"\n",
    "\n",
    "df = pd.read_csv(csv_path, low_memory=False)\n",
    "\n",
    "def normalize_columns(df):\n",
    "    df = df.copy()\n",
    "    df.columns = (\n",
    "        df.columns.str.strip()\n",
    "                  .str.lower()\n",
    "                  .str.replace(r\"\\s+\", \"_\", regex=True)\n",
    "                  .str.replace(r\"[^0-9a-zA-Z_]+\", \"\", regex=True)\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def pipe_clean(df):\n",
    "    df = normalize_columns(df).copy()\n",
    "\n",
    "    if \"price\" in df.columns:\n",
    "        df[\"price\"] = pd.to_numeric(df[\"price\"], errors=\"coerce\")\n",
    "    for c in [\"region\",\"property_type\",\"tenure\"]:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].astype(\"category\")\n",
    "\n",
    "    for c in [\"year\",\"month\"]:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "    if set([\"price\",\"region\",\"month\"]).issubset(df.columns):\n",
    "        df[\"price\"] = df.groupby([\"region\",\"month\"])[\"price\"].transform(lambda s: s.fillna(s.median()))\n",
    "        df[\"price\"] = df[\"price\"].fillna(df[\"price\"].median())\n",
    "\n",
    "    if \"price\" in df.columns:\n",
    "        q1, q3 = df[\"price\"].quantile([0.25, 0.75])\n",
    "        iqr = q3 - q1\n",
    "        lo, hi = q1 - 1.5*iqr, q3 + 1.5*iqr\n",
    "        df[\"price\"] = df[\"price\"].clip(lo, hi)\n",
    "\n",
    "    df[\"is_new_build\"] = False\n",
    "    for c in df.columns:\n",
    "        if \"new\" in c and df[c].dtype == \"object\":\n",
    "            df[\"is_new_build\"] = df[c].str.contains(\"new\", case=False, na=False)\n",
    "            break\n",
    "\n",
    "    for c in [\"unnamed_0\",\"index\"]:\n",
    "        if c in df.columns:\n",
    "            df = df.drop(columns=c)\n",
    "\n",
    "    return df\n",
    "\n",
    "df = pipe_clean(df)\n",
    "\n",
    "target = \"price\"\n",
    "base_cols = [c for c in df.columns if c != target]\n",
    "keep = []\n",
    "for c in base_cols:\n",
    "    if df[c].dtype.kind in \"biufc\":\n",
    "        keep.append(c)\n",
    "    elif str(df[c].dtype) == \"category\":\n",
    "        keep.append(c)\n",
    "\n",
    "model_df = df[keep + [target]].dropna()\n",
    "out_path = PROC_DIR / \"housing_model_ready.csv\"\n",
    "model_df.to_csv(out_path, index=False)\n",
    "print(\"Wrote:\", out_path, \"rows:\", len(model_df), \"cols:\", len(model_df.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6896fdf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned CSV  -> intermediate_data\\housing_all_cleaned.csv\n",
      "Saved cleaned PARQ -> intermediate_data\\housing_all_cleaned.parquet\n",
      "Saved model-ready CSV  -> processed_data\\housing_model_ready.csv\n",
      "Saved model-ready PARQ -> processed_data\\housing_model_ready.parquet\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# Folders (match what you used earlier)\n",
    "INT_DIR = Path(\"intermediate_data\")\n",
    "PROC_DIR = Path(\"processed_data\")\n",
    "INT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PROC_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---- 2A) Save the fully cleaned dataset (before column filtering) ----\n",
    "# Assumes your pipeline variable is named `df` after pipe_clean(...)\n",
    "clean_csv = INT_DIR / \"housing_all_cleaned.csv\"\n",
    "clean_parquet = INT_DIR / \"housing_all_cleaned.parquet\"\n",
    "\n",
    "df.to_csv(clean_csv, index=False)\n",
    "pq.write_table(pa.Table.from_pandas(df, preserve_index=False), clean_parquet)\n",
    "\n",
    "print(\"Saved cleaned CSV  ->\", clean_csv)\n",
    "print(\"Saved cleaned PARQ ->\", clean_parquet)\n",
    "\n",
    "# ---- 2B) Save the model-ready dataset (after selecting/encoding columns) ----\n",
    "# Assumes your final modeling frame is `model_df`\n",
    "model_csv = PROC_DIR / \"housing_model_ready.csv\"        # you probably already create this\n",
    "model_parquet = PROC_DIR / \"housing_model_ready.parquet\"\n",
    "\n",
    "# (Re-save CSV to be sure it's fresh; or comment this out if you already wrote it)\n",
    "model_df.to_csv(model_csv, index=False)\n",
    "\n",
    "pq.write_table(pa.Table.from_pandas(model_df, preserve_index=False), model_parquet)\n",
    "\n",
    "print(\"Saved model-ready CSV  ->\", model_csv)\n",
    "print(\"Saved model-ready PARQ ->\", model_parquet)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
